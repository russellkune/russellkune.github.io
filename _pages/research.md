---
permalink: /research/
title: "Research"
author_profile: true
redirect_from: 
  - /research.html
---

My research interests are mainly centered around statistical and computational aspects (and the interplay of the two) of modern-day machine learning techniques, motivated through considerations of how statistical methods are implemented (usually through some type of stochastic optimization procedure). In particular, here are a few topics which I’m currently thinking about:

* **Applied probabilistic modeling** – Modern machine learning methods usually consist of minimizing an empirical risk in order to find an estimate of some desired quantity of interest. However, these problems usually end up being non-convex. This is problematic as it allows for the possibility that, when trying to find a minima in practice, we instead find only a local minima which fails to be a desirable estimator – for example, we may end up returning a classification rule which fails to work well when we use it on yet unseen data. This gives rise to two questions: can we show that such `bad local minima’ do not exist, or can we design an algorithm which avoids them altogether?

* **Variational Inference for Discrete Structures** - hello 

## Papers ##

* R. Kunes\*, J. Ren\*, F. Doshi Velez. (2019) Prediction Focused Topic Models via Vocab Filtering. In AISTATS ‘20 ([link](https://arxiv.org/pdf/1910.05495.pdf))
* R. Kunes\*, J. Ren\*, F. Doshi Velez. (2020) Prediction Focused Topic Models for Electronic Health Records. Neural Information Processing Sytems Workshop in Machine Learning for Healthcare ‘19 ([link] https://arxiv.org/pdf/1911.08551.pdf)


### Pre-prints and other manuscripts ###

* R. Kunes, T. Ke, Model Based Analysis of Citation Networks. 2019. Harvard Undergraduate Senior Thesis.  ([link](https://bit.ly/31qbLE4))